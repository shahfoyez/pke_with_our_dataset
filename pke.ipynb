{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e14ff89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (2.3.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (1.21.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (2022.2.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (8.0.0)\n",
      "Requirement already satisfied: aiohttp in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: dill<0.3.6 in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (0.8.1)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (5.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.4.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from en-core-web-sm==3.4.1) (3.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.7)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.4.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.9.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.11.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.21.5)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.3)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.27.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.4)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.6.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (61.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\ashraff\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.8)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "C:\\Users\\Ashraff\\PKE-OurDataset\n",
      "C:\\ProgramData\\Anaconda3\\python39.zip\n",
      "C:\\ProgramData\\Anaconda3\\DLLs\n",
      "C:\\ProgramData\\Anaconda3\\lib\n",
      "C:\\ProgramData\\Anaconda3\n",
      "\n",
      "C:\\Users\\Ashraff\\AppData\\Roaming\\Python\\Python39\\site-packages\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\win32\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\win32\\lib\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\Pythonwin\n",
      "/PKEBenchmark\n",
      "C:\\Users\\Ashraff\\PKE-OurDataset\\pke\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/PKEBenchmark')\n",
    "import pke\n",
    "!pip install datasets\n",
    "!python -m spacy download en_core_web_sm\n",
    "for path in sys.path:\n",
    "    print(path)\n",
    "print(pke.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "364a1bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import _get_regex_pattern\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Tokenization fix for in-word hyphens (e.g. 'non-linear' would be kept \n",
    "# as one token instead of default spacy behavior of 'non', '-', 'linear')\n",
    "# https://spacy.io/usage/linguistic-features#native-tokenizer-additions\n",
    "\n",
    "from spacy.lang.char_classes import ALPHA, ALPHA_LOWER, ALPHA_UPPER\n",
    "from spacy.lang.char_classes import CONCAT_QUOTES, LIST_ELLIPSES, LIST_ICONS\n",
    "from spacy.util import compile_infix_regex\n",
    "\n",
    "# Modify tokenizer infix patterns\n",
    "infixes = (\n",
    "    LIST_ELLIPSES\n",
    "    + LIST_ICONS\n",
    "    + [\n",
    "        r\"(?<=[0-9])[+\\-\\*^](?=[0-9-])\",\n",
    "        r\"(?<=[{al}{q}])\\.(?=[{au}{q}])\".format(\n",
    "            al=ALPHA_LOWER, au=ALPHA_UPPER, q=CONCAT_QUOTES\n",
    "        ),\n",
    "        r\"(?<=[{a}]),(?=[{a}])\".format(a=ALPHA),\n",
    "        # âœ… Commented out regex that splits on hyphens between letters:\n",
    "        # r\"(?<=[{a}])(?:{h})(?=[{a}])\".format(a=ALPHA, h=HYPHENS),\n",
    "        r\"(?<=[{a}0-9])[:<>=/](?=[{a}])\".format(a=ALPHA),\n",
    "    ]\n",
    ")\n",
    "\n",
    "infix_re = compile_infix_regex(infixes)\n",
    "nlp.tokenizer.infix_finditer = infix_re.finditer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646a7cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration foyez--pakeNew-a9722485006b1613\n",
      "Reusing dataset csv (C:\\Users\\Ashraff\\.cache\\huggingface\\datasets\\foyez___csv\\foyez--pakeNew-a9722485006b1613\\0.0.0\\51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813b7647ca27432a9c6a3d1506faffb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d967ca5fe924fc6818ace7ba30abae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a46ceb5efc64fa2a87ef8d7856f9b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "# benchmark = \"inspec\"\n",
    "# benchmark = \"pake\"\n",
    "benchmark = \"pakeNew\"\n",
    "# benchmark = \"pake-m-2k\"\n",
    "\n",
    "# ayesha08/pake-m-2k\n",
    "\n",
    "\n",
    "# dataset = load_dataset('ayesha08/'+benchmark)\n",
    "dataset = load_dataset('foyez/'+benchmark)\n",
    "\n",
    "# load the inspec dataset\n",
    "# dataset = load_dataset(\"csv\", data_files={'train': 'test.csv', 'test': 'test1.csv'}, column_names=[\"title\", \"abstract\"])\n",
    "\n",
    "# pre-process training and test splits\n",
    "train = []\n",
    "for sample in tqdm(dataset['train']):\n",
    "    train.append(nlp(sample[\"title\"]+\". \"+sample[\"abstract\"]))\n",
    "test = []\n",
    "for sample in tqdm(dataset['test']):\n",
    "    test.append(nlp(sample[\"title\"]+\". \"+sample[\"abstract\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8155405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pke import compute_document_frequency, compute_lda_model\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "# computing LDA and DF counts\n",
    "\n",
    "compute_document_frequency(\n",
    "    documents=train,\n",
    "    output_file='data/{}.df.gz'.format(benchmark),\n",
    "    language='en',              # language of the input files\n",
    "    normalization='stemming',   # use porter stemmer\n",
    "    stoplist=list(punctuation), # stoplist (punctuation marks)\n",
    "    n=5                         # compute n-grams up to 5-grams\n",
    ")\n",
    "\n",
    "compute_lda_model(\n",
    "    documents=train,\n",
    "    output_file=\"data/{}.lda.pickle.gz\".format(benchmark),\n",
    "    n_topics=500,               # number of topics\n",
    "    language='en',              # language of the input files\n",
    "    stoplist=list(punctuation), # stoplist (punctuation marks)\n",
    "    normalization='stemming'    # use porter stemmer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f90fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pke import load_document_frequency_file, load_lda_model\n",
    "\n",
    "df = load_document_frequency_file(input_file='data/{}.df.gz'.format(benchmark))\n",
    "lda_model = load_lda_model(input_file=\"data/{}.lda.pickle.gz\".format(benchmark))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab70ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pke.unsupervised import *\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "outputs = {}\n",
    "elapsed_times = {}\n",
    "for model in [TfIdf, FirstPhrases, YAKE, PAKE]:\n",
    "    outputs[model.__name__] = []\n",
    "    \n",
    "    extractor = model()\n",
    "    start = timer()\n",
    "    for i, doc in enumerate(tqdm(test)):\n",
    "        extractor.load_document(input=doc, language='en')\n",
    "        extractor.grammar_selection(grammar=\"NP: {<ADJ>*<NOUN|PROPN>+}\")\n",
    "        if model.__name__ in [\"TfIdf\"]:\n",
    "            extractor.candidate_weighting(df=df)\n",
    "        elif model.__name__ in [\"TopicalPageRank\"]:\n",
    "            extractor.candidate_weighting(lda_model=lda_model)\n",
    "        else:\n",
    "            extractor.candidate_weighting()\n",
    "        outputs[model.__name__].append([u for u,v in extractor.get_n_best(n=10, stemming=True)])\n",
    "    end = timer()\n",
    "    elapsed_times[model.__name__] = end - start\n",
    "    #print(\"Elapsed time for {}: {:.2f}s - {:.2f} it/s\".format(model.__name__, end - start,  len(test) / (end - start))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087c4d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer as Stemmer\n",
    "import numpy as np\n",
    "    \n",
    "# populates the references list with stemmed keyphrases\n",
    "references = []\n",
    "\n",
    "for sample in tqdm(dataset['test']):\n",
    "    sample_keyphrases = []\n",
    "    for keyphrase in sample[\"keyphrases\"].split(','):\n",
    "        keyphrase = keyphrase.strip()\n",
    "        print(\"*************************Keyphrase*************************\")\n",
    "        print(keyphrase)\n",
    "    \n",
    "        # tokenize keyphrase\n",
    "        tokens = [token.text for token in nlp(keyphrase)]\n",
    "        \n",
    "        # normalize tokens using Porter's stemming\n",
    "        stems = [Stemmer('porter').stem(tok.lower()) for tok in tokens]\n",
    "        print(\"*************************Stemed*************************\")\n",
    "        print(stems)\n",
    "        sample_keyphrases.append(\" \".join(stems))\n",
    "       \n",
    "    print(\"*************************sample_keyphrases*************************\")\n",
    "    references.append(sample_keyphrases)\n",
    "    print(sample_keyphrases)\n",
    "\n",
    "def evaluate(top_N_keyphrases, references, cutoff=5):\n",
    "    P = len(set(top_N_keyphrases[:cutoff]) & set(references)) / len(top_N_keyphrases[:cutoff])\n",
    "    R = len(set(top_N_keyphrases[:cutoff]) & set(references)) / len(references)\n",
    "    F = (2*P*R)/(P+R) if (P+R) > 0 else 0 \n",
    "    return (P, R, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb574793",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"## Benchmarking on {}\".format(benchmark))\n",
    "print(\"| Model | it/s |  F@5 | F@10 |\")\n",
    "print(\"| :---- | ----:| ---: | ---: |\")\n",
    "\n",
    "# loop through the models\n",
    "for model in outputs:\n",
    "    \n",
    "    f_scores = []\n",
    "    # compute the P, R, F scores for the model\n",
    "    for cutoff in [5, 10]:\n",
    "        scores = []\n",
    "        for i, output in enumerate(outputs[model]):\n",
    "            scores.append(evaluate(output, references[i], cutoff))\n",
    "\n",
    "        # compute the average scores\n",
    "        P, R, F = np.mean(scores, axis=0)\n",
    "        f_scores.append(F)\n",
    "        \n",
    "    print(\"| {}  | {:.1f} | {:.2f} | {:.2f} |\".format(model,  len(test)/ elapsed_times[model], f_scores[0]*100, f_scores[1]*100))\n",
    "\n",
    "\n",
    "        # print out the performance of the model\n",
    "        #print(\"{} at {} P: {:.3f} R: {:.3f} F: {:.3f}\".format(model, cutoff, avg_scores[0], avg_scores[1], avg_scores[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9965288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "model_name = np.array([]) \n",
    "f_5 = np.array([]) \n",
    "f_10 = np.array([])\n",
    "# loop through the models\n",
    "for model in outputs:\n",
    "    \n",
    "    f_scores = []\n",
    "    # compute the P, R, F scores for the model\n",
    "    for cutoff in [5, 10]:\n",
    "        scores = []\n",
    "        for i, output in enumerate(outputs[model]):\n",
    "            scores.append(evaluate(output, references[i], cutoff))\n",
    "\n",
    "        # compute the average scores\n",
    "        P, R, F = np.mean(scores, axis=0)\n",
    "        f_scores.append(F)\n",
    "        \n",
    "    model_name = np.append(model_name, model) \n",
    "    f_5 = np.append(f_5, f_scores[0]*100) \n",
    "    f_10 = np.append(f_10, f_scores[1]*100) \n",
    "\n",
    "plt.bar(model_name, f_5)\n",
    "plt.show()\n",
    "print(\"F@5\")\n",
    "plt.bar(model_name, f_10)\n",
    "plt.show()\n",
    "print(\"F@10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2257e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e4c5db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
